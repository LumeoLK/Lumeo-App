{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6025886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "236622f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"Francesco/furniture-ngpea\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "494701ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8558a724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db866f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'image', 'width', 'height', 'objects'], dtype='str')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1ad7486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>objects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>{'id': [406], 'area': [219402], 'bbox': [[142....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>{'id': [164], 'area': [28743], 'bbox': [[268.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>{'id': [329], 'area': [206784], 'bbox': [[42.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>{'id': [379], 'area': [230545], 'bbox': [[2.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>{'id': [60], 'area': [207142], 'bbox': [[25.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                              image  width  height  \\\n",
       "0       406  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    640     640   \n",
       "1       164  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    640     640   \n",
       "2       329  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    640     640   \n",
       "3       379  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    640     640   \n",
       "4        60  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    640     640   \n",
       "\n",
       "                                             objects  \n",
       "0  {'id': [406], 'area': [219402], 'bbox': [[142....  \n",
       "1  {'id': [164], 'area': [28743], 'bbox': [[268.0...  \n",
       "2  {'id': [329], 'area': [206784], 'bbox': [[42.0...  \n",
       "3  {'id': [379], 'area': [230545], 'bbox': [[2.0,...  \n",
       "4  {'id': [60], 'area': [207142], 'bbox': [[25.0,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff4889",
   "metadata": {},
   "source": [
    "Detecting the room type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b91ac1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# # Load CLIP model (load only once)\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "# print(f\"CLIP loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f47457eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Room label\n",
    "room_labels = [\n",
    "    \"living room\",\n",
    "    \"bedroom\",\n",
    "    \"kitchen\",\n",
    "    \"bathroom\",\n",
    "    \"dining room\",\n",
    "    \"home office\",\n",
    "    \"hallway\",\n",
    "    \"study room\",\n",
    "    \"balcony\",\n",
    "    \"garage\",\n",
    "    \"gaming room\"\n",
    "]\n",
    "\n",
    "# Precompute text features (embeddings don't change. Run only once)\n",
    "text_tokens = clip.tokenize(room_labels).to(device)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f801b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_room_type(image_path, top_k=1):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\") #opens the image using Pillow\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "    img_input = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_features = model.encode_image(img_input) #encodes the images\n",
    "        img_features /= img_features.norm(dim=-1, keepdim=True) #normalize\n",
    "\n",
    "        # Cosine similarity â†’ softmax for probs\n",
    "        logits = (100.0 * img_features @ text_features.T).softmax(dim=-1)\n",
    "        probs = logits.cpu().numpy()[0]\n",
    "\n",
    "    # Top results\n",
    "    top_idx = np.argsort(probs)[::-1][:top_k]\n",
    "    \n",
    "    print(\"Top match:\")\n",
    "    results = []\n",
    "    for i, idx in enumerate(top_idx):\n",
    "        score = probs[idx] * 100\n",
    "        label = room_labels[idx]\n",
    "        print(f\"{label}\")\n",
    "        results.append((score, label))\n",
    "\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dced052",
   "metadata": {},
   "source": [
    "Extracting the colour palatte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "758fa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dominant color palette from the image\n",
    "def extract_color_palette(image_path, n_colors=6, resize_to=(400, 400)):\n",
    "   \n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    # Load image with OpenCV (BGR format)\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Failed to load image\")\n",
    "\n",
    "    # Resize for faster clustering \n",
    "    img = cv2.resize(img, resize_to)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Reshape to (pixels, 3) for K-means\n",
    "    pixels = img_rgb.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "    # Run K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_colors, n_init=10, random_state=42)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Get cluster (colors)\n",
    "    colors = kmeans.cluster_centers_.astype(int)  \n",
    "\n",
    "    # Get cluster sizes (how many pixels in each cluster)\n",
    "    labels, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "\n",
    "    # Sort colors cluster size (most dominant first)\n",
    "    sorted_indices = np.argsort(-counts)  # negative for descending\n",
    "    sorted_colors = colors[sorted_indices]\n",
    "\n",
    "    palette = [tuple(color) for color in sorted_colors]\n",
    "\n",
    "    return palette\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20044757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the colour palatte\n",
    "def show_palette(palette, block_size=60, save_path=None):\n",
    "     \n",
    "    n = len(palette)\n",
    "    height = block_size\n",
    "    width = block_size * n \n",
    "    \n",
    "    palette_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for i, color in enumerate(palette):\n",
    "        r, g, b = color\n",
    "        palette_img[:, i*block_size:(i+1)*block_size] = [r, g, b]\n",
    "    \n",
    "    pil_img = Image.fromarray(palette_img)\n",
    "    \n",
    "    if save_path:\n",
    "        pil_img.save(save_path)\n",
    "        print(f\"Palette saved to: {save_path}\")\n",
    "    else:\n",
    "        pil_img.show()  # Opens in default image viewer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f258dc",
   "metadata": {},
   "source": [
    "Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "04bcedc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top match:\n",
      "bedroom\n",
      "Palette saved to: palette_output.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image = os.path.join(\"images\", \"img2.jpeg\")   \n",
    "    \n",
    "    if not os.path.exists(image):\n",
    "        print(\"Image not found!\")\n",
    "    else:\n",
    "        try:\n",
    "            infer_room_type(image, top_k=1)\n",
    "            palette = extract_color_palette(image, n_colors=6)\n",
    "            \n",
    "            show_palette(palette, block_size=80, save_path=\"palette_output.jpg\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ead0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31fb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
